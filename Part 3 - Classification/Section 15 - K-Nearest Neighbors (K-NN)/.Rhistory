train <- prices[prices$Date<201707,]
test <- prices[prices$Date>201706,]
mod_lag6 <- lm(Caseinate_EM7_EMEA~PV_i_HCQAct_Lag6, data=train)
mod_lag6
test$pred <- predict(mod_lag6, newdata = test)
View(test)
View(prices)
View(test)
prices$Date <- paste0("01-",prices$Month,"-",prices$Year)
prices$Date <- as.Date(prices$Date, "%d-%m-%Y")
train <- prices[prices$Date<201707,]
test <- prices[prices$Date>201706,]
train <- prices[prices$Date<'2017-07-01',]
test <- prices[prices$Date>'2017-06-01',]
mod_lag6 <- lm(Caseinate_EM7_EMEA~PV_i_HCQAct_Lag6, data=train)
mod_lag6
test$pred <- predict(mod_lag6, newdata = test)
test$APE <- abs(test$Caseinate_EM7_EMEA-test$pred)/test$Caseinate_EM7_EMEA
mean(test$APE)
round(mean(test$APE)*100,2)
test$APE <- round(abs(test$Caseinate_EM7_EMEA-test$pred)*100/test$Caseinate_EM7_EMEA,2)
round(mean(test$APE)*100,2)
round(mean(test$APE),2)
library(readxl)
df <- read_excel(path = 'C:/Users/sridevi.tolety/Documents/3.FC_Strategic_Pricing/4. Working Folder/Satellites/Satellites_MasterFile.xlsx', sheet = 'Model')
names(df)
mod1 <- lm(smp_import_index~cs_index_smp, data=df)
summary(mod1)
mod1 <- lm(log(smp_import_index)~cs_index_smp, data=df)
summary(mod1)
df <- read_excel(path = 'C:/Users/sridevi.tolety/Documents/3.FC_Strategic_Pricing/4. Working Folder/Satellites/Satellites_MasterFile.xlsx', sheet = 'Model')
mod1 <- lm(log(smp_import_index)~cs_index_smp, data=df)
summary(mod1)
mod1 <- lm(smp_import_index~cs_index_smp, data=df)
summary(mod1)
View(df)
View(df)
df <- read_excel(path = 'C:/Users/sridevi.tolety/Documents/3.FC_Strategic_Pricing/4. Working Folder/Satellites/Satellites_MasterFile.xlsx', sheet = 'Model')
mod1 <- lm(log(smp_import_index)~cs_index_smp, data=df)
summary(mod1)
mod1 <- lm(smp_import_index~cs_index_smp, data=df)
summary(mod1)
# Rolling 6 month lag validation WITH SMP LAGS INCLUDED
prices <- read.csv("C:/Users/sridevi.tolety/Documents/11.FC_Apollo_Caseinate/4. Working Directory/Data/DataForTomsComparison_HannoverForecasts.csv")
prices$Date <- paste0("01-",prices$Month,"-",prices$Year)
prices$Date <- as.Date(prices$Date, "%d-%m-%Y")
dateList <-  c('2018-01-01','2018-02-01','2018-03-01','2018-04-01')
master <- data.frame()
# Rolling 6 month lag validation WITH SMP LAGS INCLUDED
prices <- read.csv("C:/Users/sridevi.tolety/Documents/11.FC_Apollo_Caseinate/4. Working Directory/Data/DataForTomsComparison_HannoverForecasts.csv")
prices$Date <- paste0("01-",prices$Month,"-",prices$Year)
prices$Date <- as.Date(prices$Date, "%d-%m-%Y")
dateList <-  c('2018-01-01','2018-02-01','2018-03-01','2018-04-01')
master <- data.frame()
for (i in dateList) {
print(i)
train <- prices[prices$Date<i,]
test <- prices[prices$Date>=i,]
test <- test[1:6,]
mod <- lm(Caseinate_EM7_EMEA ~ PV_i_HCQAct_Lag6, data=train)
mod_SMP4 <- lm(Caseinate_EM7_EMEA~PV_i_HCQAct_Lag6+SMP_Lag4, data=train)
mod_SMP6 <- lm(Caseinate_EM7_EMEA~PV_i_HCQAct_Lag6+SMP_Lag6, data=train)
test$pred <- predict(mod, newdata = test)
test$pred_SMP4 <- predict(mod_SMP4, newdata = test)
test$pred_SMP6 <- predict(mod_SMP6, newdata = test)
#Coefficients
test$Mod1_InterceptCoeff <- paste0(round(mod$coefficients[1],2))
test$Mod1_PViCoeff <- paste0(round(mod$coefficients[2],2))
test$Mod2_InterceptCoeff <- paste0(round(mod_SMP4$coefficients[1],2))
test$Mod2_PViCoeff <- paste0(round(mod_SMP4$coefficients[2],2))
test$Mod2_SMP4Coeff <- paste0(round(mod_SMP4$coefficients[3],2))
test$Mod3_InterceptCoeff <- paste0(round(mod_SMP6$coefficients[1],2))
test$Mod3_PViCoeff <- paste0(round(mod_SMP6$coefficients[2],2))
test$Mod3_SMP6Coeff <- paste0(round(mod_SMP6$coefficients[3],2))
test$APE <- round(abs(test$Caseinate_EM7_EMEA-test$pred)*100/test$Caseinate_EM7_EMEA,2)
test$APE_SMP4 <- round(abs(test$Caseinate_EM7_EMEA-test$pred_SMP4)*100/test$Caseinate_EM7_EMEA,2)
test$APE_SMP6 <- round(abs(test$Caseinate_EM7_EMEA-test$pred_SMP6)*100/test$Caseinate_EM7_EMEA,2)
test$TestBegin <- paste0(i)
test$MAPE <- paste0(round(mean(test$APE),2))
test$MAPE_SMP4 <- paste0(round(mean(test$APE_SMP4),2))
test$MAPE_SMP6 <- paste0(round(mean(test$APE_SMP6),2))
# test <- test[,c('Date','Caseinate_EM7_EMEA','pred','pred_SMP4','pred_SMP6')]
# test <- melt(test, id.vars = 'Date')
# test$Preds <- test$variable
# test$Preds[!test$variable=='Caseinate_EM7_EMEA'] <- NA
# ggplot() + geom_line(aes(x=test$Date, y=test$value, group=Preds, color=variable)) #+
# geom_point(aes(x=test$Date, y=test$pred), color='red') +
# geom_point(aes(x=test$Date, y=test$pred_SMP4), color='green') +
# geom_point(aes(x=test$Date, y=test$pred_SMP6), color='blue') + ggtitle('Test Set Predictions vs Caseinate actuals') + xlab('Month') + ylab('EM7 Caseinate Price')
# test$slope <- paste0(mod_lag6$coefficients[2])
# test$intercept <- paste0(mod_lag6$coefficients[1])
master <- rbind(master, test)
}
write.csv(master, file='C:/Users/sridevi.tolety/Desktop/temp.csv', row.names = F)
master <- data.frame()
for (i in dateList) {
print(i)
train <- prices[prices$Date<i,]
test <- prices[prices$Date>=i,]
test <- test[1:4,]
mod <- lm(Caseinate_EM7_EMEA ~ PV_i_HCQAct_Lag6, data=train)
mod_SMP4 <- lm(Caseinate_EM7_EMEA~PV_i_HCQAct_Lag6+SMP_Lag4, data=train)
mod_SMP6 <- lm(Caseinate_EM7_EMEA~PV_i_HCQAct_Lag6+SMP_Lag6, data=train)
test$pred <- predict(mod, newdata = test)
test$pred_SMP4 <- predict(mod_SMP4, newdata = test)
test$pred_SMP6 <- predict(mod_SMP6, newdata = test)
#Coefficients
test$Mod1_InterceptCoeff <- paste0(round(mod$coefficients[1],2))
test$Mod1_PViCoeff <- paste0(round(mod$coefficients[2],2))
test$Mod2_InterceptCoeff <- paste0(round(mod_SMP4$coefficients[1],2))
test$Mod2_PViCoeff <- paste0(round(mod_SMP4$coefficients[2],2))
test$Mod2_SMP4Coeff <- paste0(round(mod_SMP4$coefficients[3],2))
test$Mod3_InterceptCoeff <- paste0(round(mod_SMP6$coefficients[1],2))
test$Mod3_PViCoeff <- paste0(round(mod_SMP6$coefficients[2],2))
test$Mod3_SMP6Coeff <- paste0(round(mod_SMP6$coefficients[3],2))
test$APE <- round(abs(test$Caseinate_EM7_EMEA-test$pred)*100/test$Caseinate_EM7_EMEA,2)
test$APE_SMP4 <- round(abs(test$Caseinate_EM7_EMEA-test$pred_SMP4)*100/test$Caseinate_EM7_EMEA,2)
test$APE_SMP6 <- round(abs(test$Caseinate_EM7_EMEA-test$pred_SMP6)*100/test$Caseinate_EM7_EMEA,2)
test$TestBegin <- paste0(i)
test$MAPE <- paste0(round(mean(test$APE),2))
test$MAPE_SMP4 <- paste0(round(mean(test$APE_SMP4),2))
test$MAPE_SMP6 <- paste0(round(mean(test$APE_SMP6),2))
# test <- test[,c('Date','Caseinate_EM7_EMEA','pred','pred_SMP4','pred_SMP6')]
# test <- melt(test, id.vars = 'Date')
# test$Preds <- test$variable
# test$Preds[!test$variable=='Caseinate_EM7_EMEA'] <- NA
# ggplot() + geom_line(aes(x=test$Date, y=test$value, group=Preds, color=variable)) #+
# geom_point(aes(x=test$Date, y=test$pred), color='red') +
# geom_point(aes(x=test$Date, y=test$pred_SMP4), color='green') +
# geom_point(aes(x=test$Date, y=test$pred_SMP6), color='blue') + ggtitle('Test Set Predictions vs Caseinate actuals') + xlab('Month') + ylab('EM7 Caseinate Price')
# test$slope <- paste0(mod_lag6$coefficients[2])
# test$intercept <- paste0(mod_lag6$coefficients[1])
master <- rbind(master, test)
}
View(master)
unique(prices$Date)
i = '2018-01-01'
train <- prices[prices$Date<i,]
test <- prices[prices$Date>=i,]
View(test)
test <- test[1:4,]
#test <- test[1:4,]
mod <- lm(Caseinate_EM7_EMEA ~ PV_i_HCQAct_Lag6, data=train)
mod_SMP4 <- lm(Caseinate_EM7_EMEA~PV_i_HCQAct_Lag6+SMP_Lag4, data=train)
mod_SMP6 <- lm(Caseinate_EM7_EMEA~PV_i_HCQAct_Lag6+SMP_Lag6, data=train)
master <- data.frame()
test$pred <- predict(mod, newdata = test)
test$pred_SMP4 <- predict(mod_SMP4, newdata = test)
test$pred_SMP6 <- predict(mod_SMP6, newdata = test)
#Coefficients
test$Mod1_InterceptCoeff <- paste0(round(mod$coefficients[1],2))
test$Mod1_PViCoeff <- paste0(round(mod$coefficients[2],2))
test$Mod2_InterceptCoeff <- paste0(round(mod_SMP4$coefficients[1],2))
test$Mod2_PViCoeff <- paste0(round(mod_SMP4$coefficients[2],2))
test$Mod2_SMP4Coeff <- paste0(round(mod_SMP4$coefficients[3],2))
test$Mod3_InterceptCoeff <- paste0(round(mod_SMP6$coefficients[1],2))
test$Mod3_PViCoeff <- paste0(round(mod_SMP6$coefficients[2],2))
test$Mod3_SMP6Coeff <- paste0(round(mod_SMP6$coefficients[3],2))
test$APE <- round(abs(test$Caseinate_EM7_EMEA-test$pred)*100/test$Caseinate_EM7_EMEA,2)
test$APE_SMP4 <- round(abs(test$Caseinate_EM7_EMEA-test$pred_SMP4)*100/test$Caseinate_EM7_EMEA,2)
test$APE_SMP6 <- round(abs(test$Caseinate_EM7_EMEA-test$pred_SMP6)*100/test$Caseinate_EM7_EMEA,2)
test$TestBegin <- paste0(i)
test$MAPE <- paste0(round(mean(test$APE),2))
test$MAPE_SMP4 <- paste0(round(mean(test$APE_SMP4),2))
test$MAPE_SMP6 <- paste0(round(mean(test$APE_SMP6),2))
# test <- test[,c('Date','Caseinate_EM7_EMEA','pred','pred_SMP4','pred_SMP6')]
# test <- melt(test, id.vars = 'Date')
# test$Preds <- test$variable
# test$Preds[!test$variable=='Caseinate_EM7_EMEA'] <- NA
# ggplot() + geom_line(aes(x=test$Date, y=test$value, group=Preds, color=variable)) #+
# geom_point(aes(x=test$Date, y=test$pred), color='red') +
# geom_point(aes(x=test$Date, y=test$pred_SMP4), color='green') +
# geom_point(aes(x=test$Date, y=test$pred_SMP6), color='blue') + ggtitle('Test Set Predictions vs Caseinate actuals') + xlab('Month') + ylab('EM7 Caseinate Price')
# test$slope <- paste0(mod_lag6$coefficients[2])
# test$intercept <- paste0(mod_lag6$coefficients[1])
master <- rbind(master, test)
View(master)
i = '2018-02-01'
mod <- lm(Caseinate_EM7_EMEA ~ PV_i_HCQAct_Lag6, data=train)
summary(mod)
mod <- lm(Caseinate_EM7_EMEA ~ PV_i_HCQAct_Lag6, data=prices)
summary(mod)
prices$pred <- predict(mod, newdata = prices)
write.csv(prices, file = 'temp.csv')
getwd()
setwd("~/StudyReferences/MachineLearning_AtoZ_Udemy")
setwd("~/StudyReferences/MachineLearning_AtoZ_Udemy/Part 2 - Regression/Section 8 - Decision Tree Regression")
dataset <- read.csv('Position_Salaries.csv')
library(rpart)
X= dataset[,c(2)]
y = dataset[,c(3)]
names(dataset)
y = dataset[2:3]
rpart(Salary~Level, data=dataset )
regressor_tree = rpart(Salary~Level, data=dataset )
predict(regressor_tree, newdata = 6.5)
predict(regressor_tree, newdata = data.frame(Level=6.5))
y_pred = predict(regressor_tree, newdata = data.frame(Level=6.5)) # 249,500
ggplot(data = dataset) + geom_point(aes(x = Level, y = Salary), color = 'red') +
geom_line(aes(x = Level, y = predict(regressor_tree, newdata = dataset)), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("Level") +
ylab('Salary')
library(ggplot2)
ggplot(data = dataset) + geom_point(aes(x = Level, y = Salary), color = 'red') +
geom_line(aes(x = Level, y = predict(regressor_tree, newdata = dataset)), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("Level") +
ylab('Salary')
regressor_tree
regressor_tree = rpart(Salary~Level, data=dataset, control = rpart.control(minsplit = 1))
y_pred = predict(regressor_tree, newdata = data.frame(Level=6.5)) # 249,500
ggplot(data = dataset) + geom_point(aes(x = Level, y = Salary), color = 'red') +
geom_line(aes(x = Level, y = predict(regressor_tree, newdata = dataset)), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("Level") +
ylab('Salary')
(y_pred = predict(regressor_tree, newdata = data.frame(Level=6.5))) # 249,500
df <- read_excel(path = 'C:/Users/sridevi.tolety/Documents/3.FC_Strategic_Pricing/4. Working Folder/Satellites/Satellites_MasterFile.xlsx', sheet = 'Model')
tree_mod <- rpart(smp_import_index~cs_index_smp, data=df,
control =rpart.control(minsplit = 1))
y_pred = predict(tree_mod, newdata = df$cs_index_smp)
y_pred = predict(tree_mod, data = df$cs_index_smp)
df$y_pred = predict(tree_mod, data = df$cs_index_smp)
APE <- abs(df$smp_import_index - df$y_pred)/df$y_pred
df$APE <- abs(df$smp_import_index - df$y_pred)/df$y_pred
(MAPE <- mean(df$APE))
ggplot(data = df) + geom_point(aes(x = cs_index_smp, y = smp_import_index), color = 'red') +
geom_line(aes(x = cs_index_smp, y = df$y_pred), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("CS Index SMP") +
ylab('SMP Import Index')
tree_mod <- rpart(smp_import_index~cs_index_smp, data=df,
control =rpart.control(minsplit = 2))
df$y_pred = predict(tree_mod, data = df$cs_index_smp)
df$APE <- abs(df$smp_import_index - df$y_pred)/df$y_pred
(MAPE <- mean(df$APE)) # 17%
ggplot(data = df) + geom_point(aes(x = cs_index_smp, y = smp_import_index), color = 'red') +
geom_line(aes(x = cs_index_smp, y = df$y_pred), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("CS Index SMP") +
ylab('SMP Import Index')
ggplot(data = dataset) + geom_point(aes(x = Level, y = Salary), color = 'red') +
geom_line(aes(x = Level, y = predict(regressor_tree, newdata = dataset)), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("Level") +
ylab('Salary')
X_grid = seq(min(dataset$Level), max(dataset$Level, by= 0.01)
ggplot(data = dataset) + geom_point(aes(x = Level, y = Salary), color = 'red') +
geom_line(aes(x = X_grid, y = predict(regressor_tree, newdata = dataset)), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("Level") +
ylab('Salary')
X_grid = seq(min(dataset$Level), max(dataset$Level, by= 0.01))
ggplot(data = dataset) + geom_point(aes(x = Level, y = Salary), color = 'red') +
geom_line(aes(x = X_grid, y = predict(regressor_tree, newdata = dataset)), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("Level") +
ylab('Salary')
X_grid = seq(min(dataset$Level), max(dataset$Level, 0.01))
ggplot(data = dataset) + geom_point(aes(x = Level, y = Salary), color = 'red') +
geom_line(aes(x = X_grid, y = predict(regressor_tree, newdata = data.frame(Level=X_grid))), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("Level") +
ylab('Salary')
X_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot(data = dataset) + geom_point(aes(x = Level, y = Salary), color = 'red') +
geom_line(aes(x = X_grid, y = predict(regressor_tree, newdata = data.frame(Level=X_grid))), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("Level") +
ylab('Salary')
ggplot(data = dataset) + geom_point(aes(x = Level, y = Salary), color = 'red') +
geom_line(aes(x = X_grid, y = predict(regressor_tree, newdata = data.frame(Level=X_grid))), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("Level") +
ylab('Salary')
ggplot(data = dataset) + geom_point(aes(x = Level, y = Salary), color = 'red') +
geom_line(aes(x = Level, y = predict(regressor_tree, newdata = dataset)), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("Level") +
ylab('Salary')
ggplot(data = dataset) + geom_point(aes(x = Level, y = Salary), color = 'red') +
geom_line(aes(x = X_grid, y = predict(regressor_tree, newdata = data.frame(Level=X_grid))), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("Level") +
ylab('Salary')
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary), color = 'red') +
geom_line(aes(x = X_grid, y = predict(regressor_tree, newdata = data.frame(Level=X_grid))), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("Level") +
ylab('Salary')
setwd("~/StudyReferences/MachineLearning_AtoZ_Udemy/Part 2 - Regression/Section 9 - Random Forest Regression")
# RANDOM FOREST REGRESSION  -----------------------------------------------
setwd("~/StudyReferences/MachineLearning_AtoZ_Udemy/Part 2 - Regression/Section 9 - Random Forest Regression")
dataset <- read.csv('Position_Salaries.csv')
library(randomForest)
library(ggplot2)
X= dataset[,c(2)]
y = dataset[2:3]
regressor_rf = randomForest(Salary~Level, ntree=10, data=dataset)
(y_pred = predict(regressor_rf, newdata = data.frame(Level=6.5))) # 250,500
X_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary), color = 'red') +
geom_line(aes(x = X_grid, y = predict(regressor_rf, newdata = data.frame(Level=X_grid))), color = 'blue') +
ggtitle('Decision tree regression') +
xlab("Level") +
ylab('Salary')
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
setwd("~/StudyReferences/MachineLearning_AtoZ_Udemy/Part 3 - Classification/Section 14 - Logistic Regression")
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
View(training_set)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
# Fitting classifier to the Training set
# Create your classifier here
lr_classifier = glm(formula = Purchased~.,
family = binomial,
data = training_set)
# Predicting the Test set results
prob_pred = predict(lr_classifier, type = 'response', newdata = test_set[-3])
y_pred = ifelse(prob_pred > 0.5, 1, 0)
# Making the Confusion Matrix
cm = table(test_set[, 3], y_pred)
cm
(57+26)/nrow(test_set)# Accuracy
# Visualising the Training set results
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
colnames(grid_set) = c('Age', 'EstimatedSalary')
plot(set[, -3],
main = 'Classifier (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
# Visualising the Test set results
library(ElemStatLearn)
set = test_set
y_grid = predict(lr_classifier, newdata = grid_set)
grid_set = expand.grid(X1, X2)
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(lr_classifier, newdata = grid_set)
plot(set[, -3],
main = 'Classifier (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
prices <- read.csv("C:/Users/sridevi.tolety/Documents/11.FC_Apollo_Caseinate/4. Working Directory/Data/DataForTomsComparison.csv")
prices$Date <- paste0("01-",prices$Month,"-",prices$Year)
prices$Date <- as.Date(prices$Date, "%d-%m-%Y")
master <- data.frame()
for(i in 1:5){
print(i)
train_id <- sample(nrow(prices), size = floor(0.9*nrow(prices)), replace = F)
train <- prices[train_id,]
test <- prices[-train_id,]
mod <- lm(Caseinate_EM7_EMEA ~ PV_i_HCQAct_Lag6, data=train)
mod_SMP4 <- lm(Caseinate_EM7_EMEA~PV_i_HCQAct_Lag6+SMP_Lag4, data=train)
mod_SMP6 <- lm(Caseinate_EM7_EMEA~PV_i_HCQAct_Lag6+SMP_Lag6, data=train)
test$pred <- predict(mod, newdata = test)
test$pred_SMP4 <- predict(mod_SMP4, newdata = test)
test$pred_SMP6 <- predict(mod_SMP6, newdata = test)
#Coefficients
test$Mod1_InterceptCoeff <- paste0(round(mod$coefficients[1],2))
test$Mod1_PViCoeff <- paste0(round(mod$coefficients[2],2))
test$Mod2_InterceptCoeff <- paste0(round(mod_SMP4$coefficients[1],2))
test$Mod2_PViCoeff <- paste0(round(mod_SMP4$coefficients[2],2))
test$Mod2_SMP4Coeff <- paste0(round(mod_SMP4$coefficients[3],2))
test$Mod3_InterceptCoeff <- paste0(round(mod_SMP6$coefficients[1],2))
test$Mod3_PViCoeff <- paste0(round(mod_SMP6$coefficients[2],2))
test$Mod3_SMP6Coeff <- paste0(round(mod_SMP6$coefficients[3],2))
test$APE <- round(abs(test$Caseinate_EM7_EMEA-test$pred)*100/test$Caseinate_EM7_EMEA,2)
test$APE_SMP4 <- round(abs(test$Caseinate_EM7_EMEA-test$pred_SMP4)*100/test$Caseinate_EM7_EMEA,2)
test$APE_SMP6 <- round(abs(test$Caseinate_EM7_EMEA-test$pred_SMP6)*100/test$Caseinate_EM7_EMEA,2)
test$fold <- paste0(i)
test$MAPE <- paste0(round(mean(test$APE),2))
test$MAPE_SMP4 <- paste0(round(mean(test$APE_SMP4),2))
test$MAPE_SMP6 <- paste0(round(mean(test$APE_SMP6),2))
master <- rbind(master, test)
}
# Rolling 6 month lag validation
prices <- read.csv("C:/Users/sridevi.tolety/Documents/11.FC_Apollo_Caseinate/4. Working Directory/Data/DataForTomsComparison.csv")
prices$Date <- paste0("01-",prices$Month,"-",prices$Year)
prices$Date <- as.Date(prices$Date, "%d-%m-%Y")
dateList <-  c('2017-07-01', '2017-08-01', '2017-09-01', '2017-10-01', '2017-11-01') #,'2017-12-01','2018-01-01','2018-02-01','2018-03-01','2018-04-01')
master <- data.frame()
for (i in dateList) {
train <- prices[prices$Date<i,]
test <- prices[prices$Date>=i,]
test <- test[1:6,]
mod_lag6 <- lm(Caseinate_EM7_EMEA~PV_i_HCQAct_Lag6, data=train)
test$pred <- predict(mod_lag6, newdata = test)
test$APE <- round(abs(test$Caseinate_EM7_EMEA-test$pred)*100/test$Caseinate_EM7_EMEA,2)
test$TestBegin <- paste0(i)
test$MAPE <- paste0(round(mean(test$APE),2))
test$slope <- paste0(mod_lag6$coefficients[2])
test$intercept <- paste0(mod_lag6$coefficients[1])
master <- rbind(master, test)
master <- data.frame()
for (i in dateList) {
print(i)
train <- prices[prices$Date<i,]
test <- prices[prices$Date>=i,]
test <- test[1:6,]
mod_lag6 <- lm(Caseinate_EM7_EMEA~PV_i_HCQAct_Lag6, data=train)
test$pred <- predict(mod_lag6, newdata = test)
test$APE <- round(abs(test$Caseinate_EM7_EMEA-test$pred)*100/test$Caseinate_EM7_EMEA,2)
test$TestBegin <- paste0(i)
test$MAPE <- paste0(round(mean(test$APE),2))
test$slope <- paste0(mod_lag6$coefficients[2])
test$intercept <- paste0(mod_lag6$coefficients[1])
master <- rbind(master, test)}
# Rolling 6 month lag validation
prices <- read.csv("C:/Users/sridevi.tolety/Documents/11.FC_Apollo_Caseinate/4. Working Directory/Data/DataForTomsComparison.csv")
prices$Date <- paste0("01-",prices$Month,"-",prices$Year)
prices$Date <- as.Date(prices$Date, "%d-%m-%Y")
dateList <-  c('2017-07-01', '2017-08-01', '2017-09-01', '2017-10-01', '2017-11-01') #,'2017-12-01','2018-01-01','2018-02-01','2018-03-01','2018-04-01')
dateList <-  c('2018-01-01','2018-02-01','2018-03-01','2018-04-01')#'2017-07-01', '2017-08-01', '2017-09-01', '2017-10-01', '2017-11-01') #,'2017-12-01','2018-01-01','2018-02-01','2018-03-01','2018-04-01')
master <- data.frame()
for (i in dateList) {
print(i)
train <- prices[prices$Date<i,]
test <- prices[prices$Date>=i,]
# test <- test[1:6,]
mod_lag6 <- lm(Caseinate_EM7_EMEA~PV_i_HCQAct_Lag6, data=train)
test$pred <- predict(mod_lag6, newdata = test)
test$APE <- round(abs(test$Caseinate_EM7_EMEA-test$pred)*100/test$Caseinate_EM7_EMEA,2)
test$TestBegin <- paste0(i)
test$MAPE <- paste0(round(mean(test$APE),2))
test$slope <- paste0(mod_lag6$coefficients[2])
test$intercept <- paste0(mod_lag6$coefficients[1])
master <- rbind(master, test)}
View(master)
setwd("~/StudyReferences/MachineLearning_AtoZ_Udemy/Part 3 - Classification/Section 15 - K-Nearest Neighbors (K-NN)")
# Importing the dataset
dataset = read.csv('Social_Network_Ads.csv')
dataset = dataset[3:5]
# Encoding the target feature as factor
dataset$Purchased = factor(dataset$Purchased, levels = c(0, 1))
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split = sample.split(dataset$Purchased, SplitRatio = 0.75)
training_set = subset(dataset, split == TRUE)
test_set = subset(dataset, split == FALSE)
# Feature Scaling
training_set[-3] = scale(training_set[-3])
test_set[-3] = scale(test_set[-3])
# Predicting the Test set results
y_pred = predict(classifier, newdata = test_set[-3])
# Fitting classifier to the Training set
# Create your classifier here
library(class)
#Fitting knn to training set and fitting to test set
knn_classifier = knn(train = training_set[,-3], test = test_set[,-3], cl = training_set[,3],k = 5)
#Fitting knn to training set and fitting to test set
y_pred = knn(train = training_set[,-3], test = test_set[,-3], cl = training_set[,3],k = 5)
# Making the Confusion Matrix
cm = table(test_set[, 3], y_pred)
library(ElemStatLearn)
set = training_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = knn(train = training_set[,-3], test = X_grid, cl = training_set[,3],k = 5)
plot(set[, -3],
main = 'Classifier (Training set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
# Visualising the Test set results
library(ElemStatLearn)
set = test_set
X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)
X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)
grid_set = expand.grid(X1, X2)
colnames(grid_set) = c('Age', 'EstimatedSalary')
y_grid = predict(classifier, newdata = grid_set)
plot(set[, -3], main = 'Classifier (Test set)',
xlab = 'Age', ylab = 'Estimated Salary',
xlim = range(X1), ylim = range(X2))
contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)
points(grid_set, pch = '.', col = ifelse(y_grid == 1, 'springgreen3', 'tomato'))
points(set, pch = 21, bg = ifelse(set[, 3] == 1, 'green4', 'red3'))
